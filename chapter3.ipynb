{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing pipelines\n",
    "\n",
    "This chapter covers spaCy's processing pipelines. They are a series of functions applied to a Doc to add attributes like part-of-speech tags, dependency labels or named entities. Learn how to write custom components, and how to use custom attributes to add your own meta data to the documents, spans and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "\n",
    "model_path = os.path.join(os.getcwd(), 'models/en_core_web_md')\n",
    "nlp = spacy.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in pipeline components\n",
    "\n",
    "- tagger: part-of-speech tagger\n",
    "- parser: dependency parser\n",
    "- ner: named entity recognizer\n",
    "- textcat: text classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'custom_component']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f4cb7dac210>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f4c7a4528a0>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f4c7a452b40>)]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why custom components?\n",
    "\n",
    "![Pipeline](images/pipeline.png)\n",
    "\n",
    "- Make a function execute automatically when you call nlp\n",
    "- Add your own metadata to documents and tokens\n",
    "- Updating built-in attributes like doc.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of a component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_component(doc):\n",
    "    # Do something to the doc here\n",
    "    return doc\n",
    "\n",
    "if 'custom_component' not in nlp.pipe_names:\n",
    "  nlp.add_pipe(custom_component)\n",
    "  # nlp.add_pipe(custom_component, last=True)\n",
    "  # nlp.add_pipe(custom_component, first=True)\n",
    "  # nlp.add_pipe(custom_component, before='ner')\n",
    "  # nlp.add_pipe(custom_component, after='tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting custom attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc, Token, Span\n",
    "\n",
    "# Set extensions on the Doc, Token and Span\n",
    "Doc.set_extension('title', default=None, force=True)\n",
    "Token.set_extension('is_color', default=False, force=True)\n",
    "Span.set_extension('has_color', default=False, force=True)\n",
    "\n",
    "doc = nlp('Hello!')\n",
    "token = doc[0]\n",
    "span = doc[0:1]\n",
    "\n",
    "doc._.title = 'My document'\n",
    "token._.is_color = True\n",
    "span._.has_color = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing large volumes of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD\n",
    "#docs = [nlp(text) for text in LOTS_OF_TEXTS]\n",
    "\n",
    "# GOOD\n",
    "#docs = list(nlp.pipe(LOTS_OF_TEXTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a text 15\n",
      "And another text 16\n"
     ]
    }
   ],
   "source": [
    "# Passing in context\n",
    "data = [\n",
    "    ('This is a text', {'id': 1, 'page_number': 15}),\n",
    "    ('And another text', {'id': 2, 'page_number': 16}),\n",
    "]\n",
    "\n",
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    print(doc.text, context['page_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension('id', default=None, force=True)\n",
    "Doc.set_extension('page_number', default=None, force=True)\n",
    "\n",
    "data = [\n",
    "    ('This is a text', {'id': 1, 'page_number': 15}),\n",
    "    ('And another text', {'id': 2, 'page_number': 16}),\n",
    "]\n",
    "\n",
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    doc._.id = context['id']\n",
    "    doc._.page_number = context['page_number']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
